---
layout: article
title: 'Critical Thinking Over Coding Skills: What Educators Really Need to Know About AI'
date: '2026-02-10'
description: "Why developing critical thinking about AI matters more than learning to code for today's educators."
tags: ['ai-literacy', 'critical-thinking', 'pedagogy']
author: 'Edwin Zhao'
featured: true
readingTime: 8
---

When conversations about AI in education arise, the default recommendation from technologists is almost always the same: learn to code. While computational thinking has genuine pedagogical value, this framing fundamentally misunderstands what educators — and especially teacher educators at the university and research level — actually need to engage meaningfully with artificial intelligence. The far more urgent competency is critical thinking: the ability to evaluate AI outputs, interrogate the assumptions embedded in AI systems, and make informed judgments about when and how these tools serve educational goals. This is arguably the most important thing educators need to understand before integrating AI into their practice.

## Why Critical Thinking Comes First

The case for prioritizing critical thinking over coding rests on a straightforward observation: the vast majority of educators will interact with AI as users, not as developers. They will select AI tools for their classrooms, evaluate AI-generated content for accuracy and bias, and guide students through the ethical and epistemological questions that AI raises. None of these tasks require the ability to write a Python script. All of them require the capacity for rigorous, evidence-based reasoning about what AI systems can and cannot do. For teacher educators preparing the next generation of K-12 teachers, this distinction is not academic — it determines whether future teachers approach AI as passive consumers or as informed practitioners capable of making defensible pedagogical choices.

## Implications for Teacher Education Programs

What does this look like in practice? At the program level, it means embedding AI literacy within existing courses on research methods, curriculum design, and educational equity rather than creating standalone "AI coding" workshops that most faculty lack the background to teach well. A teacher educator in a literacy methods course, for example, can critically analyze how large language models handle reading comprehension tasks, examining where outputs align with established reading research and where they diverge. This kind of disciplinary critical engagement is far more transferable than learning prompt syntax for a specific tool that may not exist in two years.

The research literature on technological pedagogical content knowledge (TPACK) supports this approach. Effective technology integration in education has always depended more on teachers' ability to reason about the relationship between technology, content, and pedagogy than on their technical fluency with any particular tool. AI is no different. Teacher educators who can model critical evaluation of AI — questioning its sources, identifying its limitations, and situating its outputs within broader disciplinary knowledge — will produce teachers who use AI thoughtfully rather than reflexively. That is the competency that scales, and it is the one our programs should be building from the ground up.
